{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drsunithaev/Agri-Smart/blob/master/brain_tumor_detection_from_mri_images_deep_cn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EVIxaR4LUsV",
        "outputId": "c1745fc6-f664-4b30-f0b9-2950df7bfaf3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b>1.0 <span style='color:red'>|</span> Import Packages </b> <a class=\"anchor\" id=\"1.0\"></a>"
      ],
      "metadata": {
        "id": "R8O5d_ZWLOUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import shutil\n",
        "from shutil import copyfile\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from tensorflow.keras import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.offsetbox import (TextArea, DrawingArea, OffsetImage,\n",
        "                                  AnnotationBbox)\n",
        "import matplotlib.patches as mpatches\n",
        "from sklearn.utils import shuffle\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:39:40.623382Z",
          "iopub.execute_input": "2023-04-10T08:39:40.623891Z",
          "iopub.status.idle": "2023-04-10T08:39:40.633657Z",
          "shell.execute_reply.started": "2023-04-10T08:39:40.623855Z",
          "shell.execute_reply": "2023-04-10T08:39:40.632167Z"
        },
        "trusted": true,
        "id": "tiuRCZ6rLOUW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**change directory**"
      ],
      "metadata": {
        "id": "iXzUpJqxLOUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir  = '/content/drive/MyDrive/Brain'\n",
        "os.chdir(base_dir)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:39:40.636999Z",
          "iopub.execute_input": "2023-04-10T08:39:40.637565Z",
          "iopub.status.idle": "2023-04-10T08:39:40.656742Z",
          "shell.execute_reply.started": "2023-04-10T08:39:40.637516Z",
          "shell.execute_reply": "2023-04-10T08:39:40.65551Z"
        },
        "trusted": true,
        "id": "2T2DHHcDLOUa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_dir = '/content/drive/MyDrive/Brain'"
      ],
      "metadata": {
        "id": "VjpWHFOyNHOO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**get sample dataframe with class labels**"
      ],
      "metadata": {
        "id": "ySa21EcBLOUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Brain Tumor.csv\")[['Image', 'Class']]\n",
        "display(df.head())\n",
        "print(df.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:39:40.658381Z",
          "iopub.execute_input": "2023-04-10T08:39:40.65992Z",
          "iopub.status.idle": "2023-04-10T08:39:40.693835Z",
          "shell.execute_reply.started": "2023-04-10T08:39:40.659863Z",
          "shell.execute_reply": "2023-04-10T08:39:40.692581Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "kO43m5s3LOUc",
        "outputId": "d28ecdc9-44ce-4c2e-f79e-fcd374b98e0a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Image  Class\n",
              "0  Image1      0\n",
              "1  Image2      0\n",
              "2  Image3      1\n",
              "3  Image4      1\n",
              "4  Image5      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2cc29f4-efdd-4e4b-89ed-549b18d5bc08\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Image1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Image2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Image3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Image4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Image5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2cc29f4-efdd-4e4b-89ed-549b18d5bc08')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b2cc29f4-efdd-4e4b-89ed-549b18d5bc08 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b2cc29f4-efdd-4e4b-89ed-549b18d5bc08');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-705a3a33-9562-4fa3-862e-1654292a2cae\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-705a3a33-9562-4fa3-862e-1654292a2cae')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-705a3a33-9562-4fa3-862e-1654292a2cae button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3762, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b>2.0 <span style='color:red'>|</span> Rearrange Images into Training, Validation and Testing </b> <a class=\"anchor\" id=\"2.0\"></a>"
      ],
      "metadata": {
        "id": "QCHj3TbmLOUd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split files into training, validation and testing. We are using training and validation files when training the model. And we will using testing files to evaluate the final model. <br> Training: 0.8 proportion <br> Validation: 0.1 proportion <br> Testing: 0.1 proportion**"
      ],
      "metadata": {
        "id": "rcASEVrVLOUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Training + Validation with Testing Set\n",
        "def split_size(df, size):\n",
        "    return int(size * len(df))\n",
        "\n",
        "\n",
        "train_labels = df['Class'].values[:split_size(df, 0.8)]\n",
        "train_file_names = df['Image'].values[:split_size(df, 0.8)]\n",
        "\n",
        "val_labels = df['Class'].values[split_size(df, 0.8):split_size(df, 0.9)]\n",
        "val_file_names = df['Image'].values[split_size(df, 0.8):split_size(df, 0.9)]\n",
        "\n",
        "test_labels = df['Class'].values[split_size(df, 0.9):]\n",
        "test_file_names = df['Image'].values[split_size(df, 0.9):]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:39:40.696893Z",
          "iopub.execute_input": "2023-04-10T08:39:40.69728Z",
          "iopub.status.idle": "2023-04-10T08:39:40.706813Z",
          "shell.execute_reply.started": "2023-04-10T08:39:40.697229Z",
          "shell.execute_reply": "2023-04-10T08:39:40.705376Z"
        },
        "trusted": true,
        "id": "NZbbR-JILOUe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_array_labels(arr_image, arr_label):\n",
        "    arr_image_0 = arr_image[np.where(arr_label==0)]\n",
        "    arr_image_1 = arr_image[np.where(arr_label==1)]\n",
        "    return {'0':arr_image_0, '1':arr_image_1}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:39:40.708816Z",
          "iopub.execute_input": "2023-04-10T08:39:40.709325Z",
          "iopub.status.idle": "2023-04-10T08:39:40.725697Z",
          "shell.execute_reply.started": "2023-04-10T08:39:40.709243Z",
          "shell.execute_reply": "2023-04-10T08:39:40.724501Z"
        },
        "trusted": true,
        "id": "ASlumotrLOUe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_arr_dict = split_array_labels(train_file_names, train_labels)\n",
        "val_arr_dict = split_array_labels(val_file_names, val_labels)\n",
        "test_arr_dict = split_array_labels(test_file_names, test_labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:39:40.727649Z",
          "iopub.execute_input": "2023-04-10T08:39:40.728044Z",
          "iopub.status.idle": "2023-04-10T08:39:40.744055Z",
          "shell.execute_reply.started": "2023-04-10T08:39:40.728007Z",
          "shell.execute_reply": "2023-04-10T08:39:40.742684Z"
        },
        "trusted": true,
        "id": "PBPETnErLOUf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create empyty directories of training, validation and testing**"
      ],
      "metadata": {
        "id": "Rf1ipmIlLOUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_empty_directories(base_dir):\n",
        "    # in case you want to run it several times, delete the directory and create new one\n",
        "    check_exist_path = os.path.join(base_dir, '_MODELLING')\n",
        "    if os.path.isdir(check_exist_path):\n",
        "        shutil.rmtree(check_exist_path)\n",
        "        print(\"Remove old directories\")\n",
        "\n",
        "    for label in ['0','1']:\n",
        "        training_dir = os.path.join(base_dir, '_MODELLING', 'training', label)\n",
        "        validation_dir = os.path.join(base_dir, '_MODELLING', 'validation', label)\n",
        "        testing_dir = os.path.join(base_dir, '_MODELLING', 'testing', label)\n",
        "\n",
        "\n",
        "\n",
        "        os.makedirs(training_dir)\n",
        "        os.makedirs(validation_dir)\n",
        "        os.makedirs(testing_dir)\n",
        "    print(f\"Created empty  training, validation and testing directories\")\n",
        "create_empty_directories(my_dir)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:39:40.745161Z",
          "iopub.execute_input": "2023-04-10T08:39:40.745559Z",
          "iopub.status.idle": "2023-04-10T08:39:40.901525Z",
          "shell.execute_reply.started": "2023-04-10T08:39:40.745516Z",
          "shell.execute_reply": "2023-04-10T08:39:40.900358Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1ovzwncLOUh",
        "outputId": "f3e1677f-1949-4380-ce70-78cd76377f98"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Remove old directories\n",
            "Created empty  training, validation and testing directories\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split images by copying and pasting into their respective directories**"
      ],
      "metadata": {
        "id": "9Nn_BuQyLOUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(SOURCE_DIR, train_arr_dict, val_arr_dict, test_arr_dict):\n",
        "    for label in tqdm(['0','1']):\n",
        "        for file_name in train_arr_dict[label]:\n",
        "            file_name = f\"{file_name}.jpg\"\n",
        "            source = os.path.join(SOURCE_DIR, '', 'Brain Tumor', file_name)\n",
        "            # source = os.path.join(SOURCE_DIR, 'Brain Tumor', 'Brain Tumor', file_name)\n",
        "            destination = os.path.join(my_dir, '_MODELLING', 'training', label, file_name)\n",
        "            copyfile(source, destination)\n",
        "\n",
        "        for file_name in val_arr_dict[label]:\n",
        "            file_name = f\"{file_name}.jpg\"\n",
        "            source = os.path.join(SOURCE_DIR, '', 'Brain Tumor', file_name)\n",
        "            #source = os.path.join(SOURCE_DIR, 'Brain Tumor', 'Brain Tumor', file_name)\n",
        "            destination = os.path.join(my_dir, '_MODELLING', 'validation', label, file_name)\n",
        "            copyfile(source, destination)\n",
        "\n",
        "        for file_name in test_arr_dict[label]:\n",
        "            file_name = f\"{file_name}.jpg\"\n",
        "            source = os.path.join(SOURCE_DIR, '', 'Brain Tumor', file_name)\n",
        "            #source = os.path.join(SOURCE_DIR, 'Brain Tumor', 'Brain Tumor', file_name)\n",
        "            destination = os.path.join(my_dir, '_MODELLING', 'testing', label, file_name)\n",
        "            copyfile(source, destination)\n",
        "    print(f\"Created training, validation and testing directories containing images\")\n",
        "\n",
        "split_data(base_dir,train_arr_dict,val_arr_dict,test_arr_dict)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:39:40.902782Z",
          "iopub.execute_input": "2023-04-10T08:39:40.903761Z",
          "iopub.status.idle": "2023-04-10T08:39:47.819945Z",
          "shell.execute_reply.started": "2023-04-10T08:39:40.903722Z",
          "shell.execute_reply": "2023-04-10T08:39:47.818698Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "mk2Bxjp1LOUl",
        "outputId": "87b2c17d-846b-4f53-82f9-1a4d8c73e932"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/2 [00:15<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-7f25009d6b80>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Created training, validation and testing directories containing images\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_arr_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_arr_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_arr_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-7f25009d6b80>\u001b[0m in \u001b[0;36msplit_data\u001b[0;34m(SOURCE_DIR, train_arr_dict, val_arr_dict, test_arr_dict)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m#source = os.path.join(SOURCE_DIR, 'Brain Tumor', 'Brain Tumor', file_name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mdestination\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_MODELLING'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'testing'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Created training, validation and testing directories containing images\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Brain/Brain Tumor/Image3588.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b>3.0 <span style='color:red'>|</span> Show Number of Images Per Category Label </b> <a class=\"anchor\" id=\"3.0\"></a>"
      ],
      "metadata": {
        "id": "tBoMk7juLOUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir  = '/kaggle/working/_MODELLING'\n",
        "os.chdir(base_dir)\n",
        "\n",
        "mytrain_test_list = []\n",
        "mylabels_list = []\n",
        "myitem_list = []\n",
        "vis_images = []; vis_labels =[]\n",
        "\n",
        "train_test_list = tf.io.gfile.listdir(base_dir)\n",
        "for train_test in train_test_list:\n",
        "    path1 = os.path.join(base_dir, train_test)\n",
        "    label_list = tf.io.gfile.listdir(path1)\n",
        "    for label in label_list:\n",
        "        my_path = os.path.join(path1, label)\n",
        "        item_files = os.listdir(my_path)\n",
        "\n",
        "        mytrain_test_list.append(train_test)\n",
        "        mylabels_list.append(label)\n",
        "        myitem_list.append(len(item_files))\n",
        "\n",
        "        my_files = item_files[0:5]\n",
        "        for file in my_files:\n",
        "            vis_images.append(os.path.join(my_path, file))\n",
        "            vis_labels.append(label)\n",
        "\n",
        "pd.DataFrame({'Tran Test':mytrain_test_list, 'Labels':mylabels_list, \\\n",
        "              'Number of Items':myitem_list})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:39:47.824018Z",
          "iopub.execute_input": "2023-04-10T08:39:47.825298Z",
          "iopub.status.idle": "2023-04-10T08:39:47.847586Z",
          "shell.execute_reply.started": "2023-04-10T08:39:47.825195Z",
          "shell.execute_reply": "2023-04-10T08:39:47.846525Z"
        },
        "trusted": true,
        "id": "a-L0vZkFLOUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b>4.0 <span style='color:red'>|</span> Show Sample Images of Each Label </b> <a class=\"anchor\" id=\"4.0\"></a>"
      ],
      "metadata": {
        "id": "dlr66fprLOUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualising some images of each label**"
      ],
      "metadata": {
        "id": "3bWZWmzqLOUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get first 10 images for visualisation\n",
        "vis_images = vis_images[:10]\n",
        "vis_labels = vis_labels[:10]\n",
        "\n",
        "plt.figure(figsize=(12,7))\n",
        "for i in range(len(vis_labels)):\n",
        "    plt.subplot(2,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    img = mpimg.imread(vis_images[i])\n",
        "    plt.imshow(img)\n",
        "\n",
        "    if vis_labels[i] == '0':\n",
        "        my_label = 'No Tumor'\n",
        "    elif vis_labels[i] == '1':\n",
        "        my_label = 'With Tumor'\n",
        "\n",
        "    plt.xlabel(my_label)\n",
        "    plt.suptitle(f\"Classifying 2 Types of Image Labels\",fontsize=18, fontweight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:39:47.848903Z",
          "iopub.execute_input": "2023-04-10T08:39:47.850166Z",
          "iopub.status.idle": "2023-04-10T08:39:48.441025Z",
          "shell.execute_reply.started": "2023-04-10T08:39:47.850127Z",
          "shell.execute_reply": "2023-04-10T08:39:48.439671Z"
        },
        "trusted": true,
        "id": "5tSQ4_hlLOUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b>5.0 <span style='color:red'>|</span> Show Augmented Images, That Can Reduce Overfitting </b> <a class=\"anchor\" id=\"5.0\"></a>"
      ],
      "metadata": {
        "id": "2gb5ueIVLOUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to train neural networks that will be used in real-world applications, data augmentation is a crucial step. We can improve our model's ability to generalise and produce more precise predictions on data that it was not trained on by using data augmentation. <br>\n",
        "\n",
        "Data augmentation will operate concurrently with the other layers of your application on-device and will receive GPU acceleration."
      ],
      "metadata": {
        "id": "FzvkjC6HLOUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_ImageDataGenerator(vis_images, vis_labels, image_index):\n",
        "    #Loads image in from the set image path\n",
        "    class_label = vis_labels[image_index]\n",
        "    img = tf.keras.preprocessing.image.load_img(vis_images[image_index], target_size= (250,250))\n",
        "    img_tensor = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "\n",
        "    #Creates our batch of one image\n",
        "    def show_image(datagen, param):\n",
        "        pic = datagen.flow(img_tensor, batch_size =1)\n",
        "        plt.figure(figsize=(10,3.5))\n",
        "        #Plots our figures\n",
        "        for i in range(1,4):\n",
        "            plt.subplot(1, 3, i)\n",
        "            batch = pic.next()\n",
        "            image_ = batch[0].astype('uint8')\n",
        "            plt.imshow(image_)\n",
        "        plt.suptitle(f\"Class: {class_label} \\n Image Generator ({param})\",fontsize=18, fontweight='bold')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    datagen = ImageDataGenerator(rotation_range=30)\n",
        "    show_image(datagen, \"rotation_range=30\")\n",
        "\n",
        "    datagen = ImageDataGenerator(width_shift_range=0.2)\n",
        "    show_image(datagen, \"width_shift_range=0.2\")\n",
        "\n",
        "    datagen = ImageDataGenerator(zoom_range=0.2)\n",
        "    show_image(datagen, \"zoom_range=0.2\")\n",
        "\n",
        "    datagen = ImageDataGenerator(horizontal_flip=True)\n",
        "    show_image(datagen, \"horizontal_flip=True\")\n",
        "\n",
        "show_ImageDataGenerator(vis_images, vis_labels, image_index = 5)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:39:48.442725Z",
          "iopub.execute_input": "2023-04-10T08:39:48.443285Z",
          "iopub.status.idle": "2023-04-10T08:39:50.23097Z",
          "shell.execute_reply.started": "2023-04-10T08:39:48.443212Z",
          "shell.execute_reply": "2023-04-10T08:39:50.229689Z"
        },
        "trusted": true,
        "id": "azk19AtTLOUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_ImageDataGenerator(vis_images, vis_labels, image_index = 2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:39:50.232648Z",
          "iopub.execute_input": "2023-04-10T08:39:50.233034Z",
          "iopub.status.idle": "2023-04-10T08:39:52.2537Z",
          "shell.execute_reply.started": "2023-04-10T08:39:50.233001Z",
          "shell.execute_reply": "2023-04-10T08:39:52.252358Z"
        },
        "trusted": true,
        "id": "8q6NFkFpLOUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b>6.0 <span style='color:red'>|</span> Apply Image Augmentation using Image Data Generator </b> <a class=\"anchor\" id=\"6.0\"></a>"
      ],
      "metadata": {
        "id": "vj7-pLKZLOUq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " tf.keras.applications.MobileNetV2 for use as your base model. This model expects pixel values in [-1, 1], but at this point, the pixel values in your images are in [0, 255]. To rescale them, we can rescale by 1./127.5."
      ],
      "metadata": {
        "id": "nuQfP9KJLOUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_generators(TRAINING_DIR, VALIDATION_DIR, TEST_DIR):\n",
        "\n",
        "    # Instantiate the ImageDataGenerator class (don't forget to set the arguments to augment the images)\n",
        "    train_datagen = ImageDataGenerator(rescale=1./127.5,\n",
        "                                     rotation_range=30,\n",
        "                                     width_shift_range=0.2,\n",
        "                                     height_shift_range=0.2,\n",
        "                                     shear_range=0.2,\n",
        "                                     zoom_range=0.2,\n",
        "                                     horizontal_flip=True,\n",
        "                                     fill_mode='nearest')\n",
        "\n",
        "    # Pass in the appropriate arguments to the flow_from_directory method\n",
        "    train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "                                                      batch_size=32,\n",
        "                                                      class_mode='binary',\n",
        "                                                      target_size=(150, 150))\n",
        "\n",
        "    # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
        "    valid_or_test_datagen = ImageDataGenerator(rescale=1./127.5)\n",
        "\n",
        "    # Pass in the appropriate arguments to the flow_from_directory method\n",
        "    validation_generator = valid_or_test_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
        "                                                                batch_size=32,\n",
        "                                                                class_mode='binary',\n",
        "                                                                target_size=(150, 150))\n",
        "\n",
        "    test_generator = valid_or_test_datagen.flow_from_directory(directory=TEST_DIR,\n",
        "                                                                batch_size=32,\n",
        "                                                                class_mode='binary',\n",
        "                                                                target_size=(150, 150))\n",
        "    return train_generator, validation_generator, test_generator"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:39:52.255451Z",
          "iopub.execute_input": "2023-04-10T08:39:52.255803Z",
          "iopub.status.idle": "2023-04-10T08:39:52.265702Z",
          "shell.execute_reply.started": "2023-04-10T08:39:52.25577Z",
          "shell.execute_reply": "2023-04-10T08:39:52.264299Z"
        },
        "trusted": true,
        "id": "tr4unnYXLOUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_dir = os.path.join(base_dir, 'training')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "testing_dir = os.path.join(base_dir, 'testing')\n",
        "\n",
        "print(testing_dir)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:39:52.267533Z",
          "iopub.execute_input": "2023-04-10T08:39:52.2679Z",
          "iopub.status.idle": "2023-04-10T08:39:52.287911Z",
          "shell.execute_reply.started": "2023-04-10T08:39:52.267869Z",
          "shell.execute_reply": "2023-04-10T08:39:52.286659Z"
        },
        "trusted": true,
        "id": "BOWxuTBMLOUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator, validation_generator, test_generator = train_val_generators(training_dir, validation_dir, testing_dir)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:39:52.29006Z",
          "iopub.execute_input": "2023-04-10T08:39:52.290528Z",
          "iopub.status.idle": "2023-04-10T08:39:52.621121Z",
          "shell.execute_reply.started": "2023-04-10T08:39:52.290491Z",
          "shell.execute_reply": "2023-04-10T08:39:52.619951Z"
        },
        "trusted": true,
        "id": "TITy0-08LOUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b>7.0 <span style='color:red'>|</span> Get Transfer Learning Model - MobileNetV2 </b> <a class=\"anchor\" id=\"7.0\"></a>"
      ],
      "metadata": {
        "id": "G0VQrVwyLOUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MobileNet-v2 is a convolutional neural network consisting of 53 layers deep. The ImageNet database contains a pretrained version of the network that has been trained on more than a million images [1]. The pretrained network can categorise photos into 1000 different object categories. It is good to have a good sense of initialisation of parameters. So we will freeze the top layers of MovileNetV2 first and train on the last output layers."
      ],
      "metadata": {
        "id": "HdWSrsGfLOUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(input_shape=(150, 150, 3),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "base_model.trainable = False\n",
        "last_output = base_model.output\n",
        "num_trainable_params = sum([w.shape.num_elements() for w in base_model.trainable_weights])\n",
        "\n",
        "print(f\"There are {num_trainable_params:,} trainable parameters in this model.\")\n",
        "print(f\"The pretrained model has type: {type(base_model)}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:39:52.62282Z",
          "iopub.execute_input": "2023-04-10T08:39:52.623779Z",
          "iopub.status.idle": "2023-04-10T08:39:54.019219Z",
          "shell.execute_reply.started": "2023-04-10T08:39:52.623728Z",
          "shell.execute_reply": "2023-04-10T08:39:54.017966Z"
        },
        "trusted": true,
        "id": "GI8kHAMbLOUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b>8.0 <span style='color:red'>|</span> Building Deep Neural Network Architecture with MobileNetV2 </b> <a class=\"anchor\" id=\"8.0\"></a>"
      ],
      "metadata": {
        "id": "ciiVIDSpLOUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transfer_learning(last_output, pre_trained_model):\n",
        "    # Flatten the output layer to 1 dimension\n",
        "    x = tf.keras.layers.Flatten()(last_output)\n",
        "    # Add a fully connected layer with 1024 hidden units and ReLU activation\n",
        "    x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "    # Add a dropout rate of 0.6\n",
        "    x = tf.keras.layers.Dropout(0.6)(x)\n",
        "    # Add a final sigmoid layer for classification\n",
        "    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "    # Create the complete model by using the Model class\n",
        "    model = Model(inputs=pre_trained_model.input, outputs=x)\n",
        "\n",
        "    return model\n",
        "\n",
        "model = transfer_learning(last_output, base_model)\n",
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:39:54.022476Z",
          "iopub.execute_input": "2023-04-10T08:39:54.02301Z",
          "iopub.status.idle": "2023-04-10T08:39:54.472317Z",
          "shell.execute_reply.started": "2023-04-10T08:39:54.022959Z",
          "shell.execute_reply": "2023-04-10T08:39:54.471127Z"
        },
        "trusted": true,
        "id": "n8kev66FLOUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = transfer_learning(last_output, base_model)\n",
        "\n",
        "print(f\"Total Trainable Variables: {len(model.trainable_variables)}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:39:54.473851Z",
          "iopub.execute_input": "2023-04-10T08:39:54.475059Z",
          "iopub.status.idle": "2023-04-10T08:39:54.728166Z",
          "shell.execute_reply.started": "2023-04-10T08:39:54.475018Z",
          "shell.execute_reply": "2023-04-10T08:39:54.726461Z"
        },
        "trusted": true,
        "id": "cBP0ILhnLOUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This callback will stop the training when there is no improvement in\n",
        "the validation loss for three consecutive epochs."
      ],
      "metadata": {
        "id": "yDPdoEZGLOUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:39:54.729992Z",
          "iopub.execute_input": "2023-04-10T08:39:54.730993Z",
          "iopub.status.idle": "2023-04-10T08:39:54.738068Z",
          "shell.execute_reply.started": "2023-04-10T08:39:54.730949Z",
          "shell.execute_reply": "2023-04-10T08:39:54.735639Z"
        },
        "trusted": true,
        "id": "Wb8E4E44LOUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0003),\n",
        "            loss = 'binary_crossentropy',\n",
        "            metrics=['accuracy'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:39:54.742892Z",
          "iopub.execute_input": "2023-04-10T08:39:54.743309Z",
          "iopub.status.idle": "2023-04-10T08:39:54.764999Z",
          "shell.execute_reply.started": "2023-04-10T08:39:54.743252Z",
          "shell.execute_reply": "2023-04-10T08:39:54.763615Z"
        },
        "trusted": true,
        "id": "isLjpfcALOUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator,\n",
        "                    epochs=10,\n",
        "                    validation_data=validation_generator,\n",
        "                    callbacks=[callback])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:39:54.766487Z",
          "iopub.execute_input": "2023-04-10T08:39:54.766855Z",
          "iopub.status.idle": "2023-04-10T08:45:21.647636Z",
          "shell.execute_reply.started": "2023-04-10T08:39:54.766821Z",
          "shell.execute_reply": "2023-04-10T08:45:21.646498Z"
        },
        "trusted": true,
        "id": "85sEn-KdLOUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vis_evaluation(history_dict, model_name):\n",
        "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15, 10))\n",
        "    epochs = range(1, len(history_dict['accuracy'])+1)\n",
        "\n",
        "    def get_gradient(y_arr, epochs):\n",
        "        return round((y_arr[-1] - y_arr[0]) / (epochs[-1] - epochs[0]),2)\n",
        "\n",
        "    def vis_sub_evaluation(n, Accuracy, train_acc, val_acc, epochs):\n",
        "        axs[n].plot(epochs, train_acc, label=f'Training {Accuracy}', ls='--')\n",
        "        axs[n].plot(epochs, val_acc, label=f'Validation {Accuracy}', ls='dotted')\n",
        "\n",
        "        axs[n].set_title(f'Training and Validation {Accuracy}')\n",
        "        axs[n].set_xlabel('Epochs')\n",
        "        axs[n].set_ylabel(Accuracy)\n",
        "\n",
        "        handles, labels = axs[n].get_legend_handles_labels()\n",
        "        m_patch = mpatches.Patch(color='grey',label='m: gradient')\n",
        "        handles.append(m_patch)\n",
        "        axs[n].legend(handles=handles)\n",
        "\n",
        "        def annotate_box(train_acc):\n",
        "            return AnnotationBbox(TextArea(f\"m = {get_gradient(train_acc, epochs)}\"), (epochs[-1], train_acc[-1]),\n",
        "                            xybox=(20, 20),\n",
        "                            xycoords='data',\n",
        "                            boxcoords=\"offset points\",\n",
        "                            arrowprops=dict(arrowstyle=\"->\"))\n",
        "        axs[n].add_artist(annotate_box(train_acc))\n",
        "        axs[n].add_artist(annotate_box(val_acc))\n",
        "\n",
        "    train_acc = history_dict['accuracy']\n",
        "    val_acc = history_dict['val_accuracy']\n",
        "    vis_sub_evaluation(0, 'Accuracy', train_acc, val_acc, epochs)\n",
        "\n",
        "    train_loss = history_dict['loss']\n",
        "    val_loss = history_dict['val_loss']\n",
        "    vis_sub_evaluation(1, 'Loss', train_loss, val_loss, epochs)\n",
        "\n",
        "    plt.suptitle(f\"Performance Evaluation of {model_name}\",fontsize=18, fontweight='bold')\n",
        "    plt.show()\n",
        "\n",
        "history_dict_1 = history.history\n",
        "vis_evaluation(history_dict_1, 'Transfer Learning MobileNetV2')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:45:21.649212Z",
          "iopub.execute_input": "2023-04-10T08:45:21.64961Z",
          "iopub.status.idle": "2023-04-10T08:45:51.816608Z",
          "shell.execute_reply.started": "2023-04-10T08:45:21.649577Z",
          "shell.execute_reply": "2023-04-10T08:45:51.815196Z"
        },
        "trusted": true,
        "id": "Lh19eHq5LOU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b>9.0 <span style='color:red'>|</span> Fine Tuning Transfer Learning Model </b> <a class=\"anchor\" id=\"9.0\"></a>"
      ],
      "metadata": {
        "id": "0sY7l_1PLOU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 100\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "print(f\"Total Trainable Variables: {len(model.trainable_variables)}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:45:51.818241Z",
          "iopub.execute_input": "2023-04-10T08:45:51.818651Z",
          "iopub.status.idle": "2023-04-10T08:45:51.837586Z",
          "shell.execute_reply.started": "2023-04-10T08:45:51.818618Z",
          "shell.execute_reply": "2023-04-10T08:45:51.83613Z"
        },
        "trusted": true,
        "id": "tCfn8fa6LOU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001/10),\n",
        "            loss = 'binary_crossentropy',\n",
        "            metrics=['accuracy'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:45:51.839334Z",
          "iopub.execute_input": "2023-04-10T08:45:51.83978Z",
          "iopub.status.idle": "2023-04-10T08:45:51.854991Z",
          "shell.execute_reply.started": "2023-04-10T08:45:51.839744Z",
          "shell.execute_reply": "2023-04-10T08:45:51.853418Z"
        },
        "trusted": true,
        "id": "CXNopzaYLOU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_fine = model.fit(train_generator,\n",
        "                         epochs=15,\n",
        "                         initial_epoch=history.epoch[-1],\n",
        "                         validation_data=validation_generator)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:45:51.856782Z",
          "iopub.execute_input": "2023-04-10T08:45:51.85734Z",
          "iopub.status.idle": "2023-04-10T08:59:33.057686Z",
          "shell.execute_reply.started": "2023-04-10T08:45:51.857293Z",
          "shell.execute_reply": "2023-04-10T08:59:33.056475Z"
        },
        "trusted": true,
        "id": "jZf1NvleLOU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict_2 = history_fine.history\n",
        "vis_evaluation(history_dict_2, 'Fine-Tuned Transfer Learning MobileNetV2')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:59:33.059697Z",
          "iopub.execute_input": "2023-04-10T08:59:33.060133Z",
          "iopub.status.idle": "2023-04-10T08:59:33.615507Z",
          "shell.execute_reply.started": "2023-04-10T08:59:33.060093Z",
          "shell.execute_reply": "2023-04-10T08:59:33.614248Z"
        },
        "trusted": true,
        "id": "QmdasnIvLOU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b>10.0 <span style='color:red'>|</span> Evaluation on Unseen Data </b> <a class=\"anchor\" id=\"10.0\"></a>"
      ],
      "metadata": {
        "id": "dgKes_PALOU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print('Test accuracy :', accuracy)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:59:33.61703Z",
          "iopub.execute_input": "2023-04-10T08:59:33.618107Z",
          "iopub.status.idle": "2023-04-10T08:59:36.839Z",
          "shell.execute_reply.started": "2023-04-10T08:59:33.618066Z",
          "shell.execute_reply": "2023-04-10T08:59:36.83811Z"
        },
        "trusted": true,
        "id": "445rOOgILOU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b>11.0 <span style='color:red'>|</span> Visualise Predictions on Unseen Data"
      ],
      "metadata": {
        "id": "e9Ei03CqLOU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_paths = [] ; selected_labels = []\n",
        "testing_path_0 = os.path.join(base_dir, 'testing', '0')\n",
        "for x in random.sample(os.listdir(testing_path_0),10):\n",
        "    selected_paths.append(os.path.join(testing_path_0, x))\n",
        "    selected_labels.append(0)\n",
        "\n",
        "testing_path_1 = os.path.join(base_dir, 'testing', '1')\n",
        "for x in random.sample(os.listdir(testing_path_1),10):\n",
        "    selected_paths.append(os.path.join(testing_path_1, x))\n",
        "    selected_labels.append(1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:59:36.839966Z",
          "iopub.execute_input": "2023-04-10T08:59:36.840297Z",
          "iopub.status.idle": "2023-04-10T08:59:36.849519Z",
          "shell.execute_reply.started": "2023-04-10T08:59:36.840254Z",
          "shell.execute_reply": "2023-04-10T08:59:36.848279Z"
        },
        "trusted": true,
        "id": "auP_Xvj5LOU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = shuffle(selected_paths, selected_labels, random_state=0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:59:36.851463Z",
          "iopub.execute_input": "2023-04-10T08:59:36.851948Z",
          "iopub.status.idle": "2023-04-10T08:59:36.861819Z",
          "shell.execute_reply.started": "2023-04-10T08:59:36.8519Z",
          "shell.execute_reply": "2023-04-10T08:59:36.860741Z"
        },
        "trusted": true,
        "id": "vp07I7hsLOU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for vis_image, y_true in zip(X, y):\n",
        "    img = image.load_img(vis_image, target_size=(150, 150))\n",
        "    x = image.img_to_array(img)\n",
        "    x /= 127.5\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    preprocess_images = np.vstack([x])\n",
        "    classes = model.predict(preprocess_images, batch_size=10)\n",
        "    score = tf.nn.sigmoid(classes[0])\n",
        "    if classes[0]>0.5:\n",
        "        predicted_label = 1\n",
        "    else:\n",
        "        predicted_label =0\n",
        "    plt.title(f'True Label: {y_true} \\n Predicted Label: {predicted_label} with a {100 * np.max(score):.2f} percent confidence.')\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:59:36.863711Z",
          "iopub.execute_input": "2023-04-10T08:59:36.864206Z",
          "iopub.status.idle": "2023-04-10T08:59:44.206505Z",
          "shell.execute_reply.started": "2023-04-10T08:59:36.864158Z",
          "shell.execute_reply": "2023-04-10T08:59:44.205291Z"
        },
        "trusted": true,
        "id": "w23v7ARMLOU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b>12.0 <span style='color:red'>|</span> What Computer see during training convolutional images </b> <a class=\"anchor\" id=\"11.0\"></a>"
      ],
      "metadata": {
        "id": "htsirb_mLOU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a new Model that will take an image as input, and will output\n",
        "# intermediate representations for all layers in the previous model\n",
        "successive_outputs = [layer.output for layer in model.layers]\n",
        "visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n",
        "\n",
        "# Prepare a random input image from the training set.\n",
        "adult_img_files = vis_images[:5]\n",
        "child_img_files = vis_images[5:10]\n",
        "img_path = random.choice(adult_img_files + child_img_files)\n",
        "img = load_img(img_path, target_size=(150, 150))  # this is a PIL image\n",
        "x   = img_to_array(img)                           # Numpy array with shape (150, 150, 3)\n",
        "x   = x.reshape((1,) + x.shape)                   # Numpy array with shape (1, 150, 150, 3)\n",
        "\n",
        "# Scale by 1/255\n",
        "x /= 255.0\n",
        "\n",
        "# Run the image through the network, thus obtaining all\n",
        "# intermediate representations for this image.\n",
        "successive_feature_maps = visualization_model.predict(x)\n",
        "\n",
        "# These are the names of the layers, so you can have them as part of our plot\n",
        "layer_names = [layer.name for layer in model.layers]\n",
        "\n",
        "# Display the representations\n",
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "\n",
        "  if len(feature_map.shape) == 4:\n",
        "\n",
        "    #-------------------------------------------\n",
        "    # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
        "    #-------------------------------------------\n",
        "    n_features = feature_map.shape[-1]  # number of features in the feature map\n",
        "    size       = feature_map.shape[ 1]  # feature map shape (1, size, size, n_features)\n",
        "\n",
        "    # Tile the images in this matrix\n",
        "    display_grid = np.zeros((size, size * n_features))\n",
        "\n",
        "    #-------------------------------------------------\n",
        "    # Postprocess the feature to be visually palatable\n",
        "    #-------------------------------------------------\n",
        "    for i in range(n_features):\n",
        "        x  = feature_map[0, :, :, i]\n",
        "        x -= x.mean()\n",
        "        x /= x.std ()\n",
        "        x *=  64\n",
        "        x += 128\n",
        "        x  = np.clip(x, 0, 255).astype('uint8')\n",
        "        display_grid[:, i * size : (i + 1) * size] = x # Tile each filter into a horizontal grid\n",
        "\n",
        "    #-----------------\n",
        "    # Display the grid\n",
        "    #-----------------\n",
        "    scale = 20. / n_features\n",
        "    plt.figure( figsize=(scale * n_features, scale) )\n",
        "    plt.title ( layer_name )\n",
        "    plt.grid  ( False )\n",
        "    plt.imshow( display_grid, aspect='auto', cmap='viridis' )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T08:59:44.208695Z",
          "iopub.execute_input": "2023-04-10T08:59:44.209101Z",
          "iopub.status.idle": "2023-04-10T09:00:17.857154Z",
          "shell.execute_reply.started": "2023-04-10T08:59:44.209064Z",
          "shell.execute_reply": "2023-04-10T09:00:17.855838Z"
        },
        "trusted": true,
        "id": "jqCMQL-bLOU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b>13.0 <span style='color:red'>|</span> Test Your Own Images </b> <a class=\"anchor\" id=\"13.0\"></a>"
      ],
      "metadata": {
        "id": "HqbebEeTLOVA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, you can enjoy the model prediction by using your own images."
      ],
      "metadata": {
        "id": "WhQR0090LOVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_your_prediction(YOUR_IMAGE_PATH = None):\n",
        "    if YOUR_IMAGE_PATH == None:\n",
        "        YOUR_IMAGE_PATH = '/kaggle/working/_MODELLING/testing/1/Image3702.jpg'\n",
        "\n",
        "    img = image.load_img(YOUR_IMAGE_PATH, target_size=(150, 150))\n",
        "    plt.imshow(img)\n",
        "    x = image.img_to_array(img)\n",
        "    x /= 127.5\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    images = np.vstack([x])\n",
        "    classes = model.predict(images, batch_size=10)\n",
        "    score = tf.nn.sigmoid(classes[0])\n",
        "\n",
        "    class_name = train_generator.class_indices\n",
        "    class_name_inverted = {y: x for x, y in class_name.items()}\n",
        "\n",
        "    if classes[0]>0.5:\n",
        "        print(f\" This image most likely belongs to '{class_name_inverted[1]}' (With Tumor) at {100 * np.max(score):.2f} percent confidence.\")\n",
        "    else:\n",
        "        print(f\" This image most likely belongs to '{class_name_inverted[0]}' (Without Tumor) at {100 * np.max(score):.2f} percent confidence.\")\n",
        "\n",
        "make_your_prediction(YOUR_IMAGE_PATH = None)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-10T09:13:36.981363Z",
          "iopub.execute_input": "2023-04-10T09:13:36.982031Z",
          "iopub.status.idle": "2023-04-10T09:13:37.277216Z",
          "shell.execute_reply.started": "2023-04-10T09:13:36.98199Z",
          "shell.execute_reply": "2023-04-10T09:13:37.275827Z"
        },
        "trusted": true,
        "id": "sujeL-EiLOVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# References\n",
        "1. Deng J, Dong W, Socher R, Li L-J, Li K, Fei-Fei L. Imagenet: A large-scale hierarchical image database. In: 2009 IEEE conference on computer vision and pattern recognition. 2009. p. 24855."
      ],
      "metadata": {
        "id": "F6ogBv7FLOVC"
      }
    }
  ]
}